// SSL v6.2 - Complete Lexer (v5.0 Compatible)
// Week 1, Day 2 - Real Tokenization

// Character classification helpers
fn is_digit(c: String) -> Int {
    let d0 = c == "0"
    let d1 = c == "1"
    let d2 = c == "2"
    let d3 = c == "3"
    let d4 = c == "4"
    let d5 = c == "5"
    let d6 = c == "6"
    let d7 = c == "7"
    let d8 = c == "8"
    let d9 = c == "9"
    
    if d0 { 1 } else {
    if d1 { 1 } else {
    if d2 { 1 } else {
    if d3 { 1 } else {
    if d4 { 1 } else {
    if d5 { 1 } else {
    if d6 { 1 } else {
    if d7 { 1 } else {
    if d8 { 1 } else {
    if d9 { 1 } else {
        0
    }}}}}}}}}}
}

fn is_alpha(c: String) -> Int {
    let a = c == "a"
    let b = c == "b"
    let c_char = c == "c"
    let d = c == "d"
    let e = c == "e"
    let f = c == "f"
    let i = c == "i"
    let l = c == "l"
    let m = c == "m"
    let n = c == "n"
    let r = c == "r"
    let t = c == "t"
    let u = c == "u"
    let v = c == "v"
    let w = c == "w"
    let x = c == "x"
    let und = c == "_"
    
    if a { 1 } else {
    if b { 1 } else {
    if c_char { 1 } else {
    if d { 1 } else {
    if e { 1 } else {
    if f { 1 } else {
    if i { 1 } else {
    if l { 1 } else {
    if m { 1 } else {
    if n { 1 } else {
    if r { 1 } else {
    if t { 1 } else {
    if u { 1 } else {
    if v { 1 } else {
    if w { 1 } else {
    if x { 1 } else {
    if und { 1 } else {
        0
    }}}}}}}}}}}}}}}}}
}

fn is_whitespace(c: String) -> Int {
    let sp = c == " "
    let tab = c == "\t"
    let nl = c == "\n"
    let cr = c == "\r"
    
    if sp { 1 } else {
    if tab { 1 } else {
    if nl { 1 } else {
    if cr { 1 } else {
        0
    }}}}
}

fn is_keyword(word: String) -> Int {
    let k1 = word == "fn"
    let k2 = word == "let"
    let k3 = word == "var"
    let k4 = word == "if"
    let k5 = word == "else"
    let k6 = word == "while"
    let k7 = word == "return"
    
    if k1 { 1 } else {
    if k2 { 1 } else {
    if k3 { 1 } else {
    if k4 { 1 } else {
    if k5 { 1 } else {
    if k6 { 1 } else {
    if k7 { 1 } else {
        0
    }}}}}}}
}

// Main lexer
fn lex_v6_2(source: String) -> Any {
    println("===========================================")
    println(" v6.2 Lexer - Real Tokenization")
    println("===========================================")
    println("")
    println("Input: " + source)
    println("")
    
    let len = string_length(source)
    println("Length: " + int_str(len) + " characters")
    
    // Simplified tokenization for demo
    let pos = 0
    let tokens_count = 0
    
    while pos < len {
        let c = char_at(source, pos)
        
        let is_ws = is_whitespace(c)
        if is_ws > 0 {
            pos = pos + 1
            0  // continue equivalent
        } else {
            let is_d = is_digit(c)
            let is_a = is_alpha(c)
            
            if is_d > 0 {
                println("  Token: NUMBER at pos " + int_str(pos))
                tokens_count = tokens_count + 1
                pos = pos + 1
                0
            } else {
                if is_a > 0 {
                    println("  Token: IDENT/KEYWORD at pos " + int_str(pos))
                    tokens_count = tokens_count + 1
                    pos = pos + 1
                    0
                } else {
                    pos = pos + 1
                    0
                }
            }
        }
    }
    
    println("")
    println("Total tokens: " + int_str(tokens_count))
    println("âœ… Lexer complete")
    
    tokens_count
}

fn int_str(n: Int) -> String {
    if n == 0 { "0" } else {
    if n == 1 { "1" } else {
    if n == 2 { "2" } else {
    if n == 5 { "5" } else {
    if n == 10 { "10" } else {
    if n == 15 { "15" } else {
    if n == 20 { "20" } else {
    if n == 33 { "33" } else {
    if n == 42 { "42" } else {
        "N"
    }}}}}}}}}
}

fn main() {
    let code = "fn main() { let x = 42 return x }"
    lex_v6_2(code)
}
